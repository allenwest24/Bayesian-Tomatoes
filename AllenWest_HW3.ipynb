{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AllenWest_HW3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "author": [
      {
        "@type": "Person",
        "name": "Kevin Gold"
      }
    ]
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2itSY-L1zv6K"
      },
      "source": [
        "# 4100 Assignment 3: Bayesian Tomatoes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKb47fhOzzDM"
      },
      "source": [
        "In this assignment, you’ll implement a “sentiment analysis” classifier that looks at sentences and decides how positive or negative the speaker is feeling. In fact, you’ll implement two: a Naive Bayes classifier that uses each word as a piece of independent evidence, and classifier that treats each word as dependent on the last. This assignment will also serve as your introduction to machine learning.\n",
        "\n",
        "The data we’ll be using consists of sentences pulled from the Rotten Tomatoes movie review aggregator website.  In this dataset, someone has gone through each sentence and labeled the sentiment as belonging to one of 5 categories:\n",
        "\n",
        "0 - negative\n",
        "\n",
        "1 - somewhat negative\n",
        "\n",
        "2 - neutral\n",
        "\n",
        "3 - somewhat positive\n",
        "\n",
        "4 - positive\n",
        "\n",
        "(In fact, the dataset has also labeled phrases within the sentence with these sentiments, but the loader will just skip anything that isn't a full sentence.)\n",
        "This dataset, known as SST1, can be found on Canvas in the same place where you found this notebook.  The following code will upload it into a \"dataframe\" (annotated multidimensional array) if you select the file at the prompt."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtCqfk-v0lQa",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "8c5fc484-94d9-4b38-b99a-c5975f15ebe9"
      },
      "source": [
        "import io\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "df = pd.read_table(io.BytesIO(uploaded['train.tsv']))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ca0c1a0a-a2b6-418f-b42a-7c65b1f95d85\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ca0c1a0a-a2b6-418f-b42a-7c65b1f95d85\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving train.tsv to train.tsv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ep_EsTFTOyk"
      },
      "source": [
        "You can see some of the dataframe's contents by just evaluating it at the prompt.  (You can also just open .tsv files as text files on your local machine.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpduykvfStSA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "84665942-3a57-421e-c124-7a7f1a09bc66"
      },
      "source": [
        "df"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156055</th>\n",
              "      <td>156056</td>\n",
              "      <td>8544</td>\n",
              "      <td>Hearst 's</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156056</th>\n",
              "      <td>156057</td>\n",
              "      <td>8544</td>\n",
              "      <td>forced avuncular chortles</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156057</th>\n",
              "      <td>156058</td>\n",
              "      <td>8544</td>\n",
              "      <td>avuncular chortles</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156058</th>\n",
              "      <td>156059</td>\n",
              "      <td>8544</td>\n",
              "      <td>avuncular</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156059</th>\n",
              "      <td>156060</td>\n",
              "      <td>8544</td>\n",
              "      <td>chortles</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>156060 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        PhraseId  ...  Sentiment\n",
              "0              1  ...          1\n",
              "1              2  ...          2\n",
              "2              3  ...          2\n",
              "3              4  ...          2\n",
              "4              5  ...          2\n",
              "...          ...  ...        ...\n",
              "156055    156056  ...          2\n",
              "156056    156057  ...          1\n",
              "156057    156058  ...          3\n",
              "156058    156059  ...          2\n",
              "156059    156060  ...          2\n",
              "\n",
              "[156060 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aQBHsQfTiUp"
      },
      "source": [
        "The following class's methods do all the necessary counting to transform this data into counts that you can use to estimate probabilities for a Naive Bayes classifier.  Its function for breaking down sentences into tokens is also pulled out for your later use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaeTUf9_UFj8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76d1a16f-0cf1-4e92-e93a-bbbc6aca3cd5"
      },
      "source": [
        "# NLTK is a great toolkit that makes Python a nice choice for natural language processing (NLP)\n",
        "# Note that bigrams() returns an *iterator* and not a *list* - you would need to call it\n",
        "# again or store as a list to iterate over the bigrams multiple times\n",
        "\n",
        "# This statement needed to avoid erroring out.\n",
        "!pip3 install nltk==3.4\n",
        "\n",
        "from nltk.util import bigrams\n",
        "\n",
        "def tokenize(sentence):\n",
        "    \"\"\" Returns list of tokens (strings) from the sentence.\n",
        "\n",
        "    Sets to lowercase and separates tokens by whitespace.\n",
        "\n",
        "    Args:\n",
        "        sentence (string):  the string to tokenize\n",
        "    \"\"\"\n",
        "    return [t.lower() for t in sentence.split()]\n",
        "\n",
        "class ModelInfo:\n",
        "    \"\"\" Contains all counts from the data necessary to do Naive Bayes.\n",
        "\n",
        "    Attributes:\n",
        "        word_counts (List[Dict[string,int]]):  counts of tokens, indexed by class\n",
        "        bigram_counts (List[Dict[string,int]]): as word_counts, but for bigrams\n",
        "        sentiment_counts (List[int]):  counts of sentences with each sentiment\n",
        "        total_words (List[int]):  counts of words in each sentiment\n",
        "        bigram_denoms (List[Dict[string,int]]):  counts of how often a token starts a bigram,\n",
        "                                                 again one per sentiment.\n",
        "        total_bigrams (List[int]): counts of total bigrams for each sentiment\n",
        "        total_examples (int):  total sentence count\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.word_counts = [{}, {}, {}, {}, {}]\n",
        "        self.bigram_counts = [{}, {}, {}, {}, {}]\n",
        "        self.sentiment_counts = [0, 0, 0, 0, 0]\n",
        "        self.total_words = [0, 0, 0, 0, 0]\n",
        "        self.bigram_denoms = [{}, {}, {}, {}, {}]\n",
        "        self.total_bigrams = [0, 0, 0, 0, 0]\n",
        "        self.total_examples = 0\n",
        "\n",
        "    def __str__(self):\n",
        "        words = self.total_words\n",
        "        sentiments = self.sentiment_counts\n",
        "        return \"words by sentiment: {} sentences: {}\".format(words, sentiments)\n",
        "\n",
        "    def update_word_counts(self, sentence, sentiment):\n",
        "        \"\"\" Consume a sentence and update all counts.\n",
        "\n",
        "        To \"tokenize\" the sentence we'll make use of NLTK, a widely-used Python natural language\n",
        "        processing (NLP) library.  This will handle otherwise onerous tasks like separating periods\n",
        "        from their attached words.  (Unless the periods are decimal points ... it's more complex\n",
        "        than you might think.)  The result of tokenization is a list of individual strings that are\n",
        "        words or their equivalent.\n",
        "\n",
        "        Args:\n",
        "            sentence (string):  The example sentence.\n",
        "            sentiment (int):  The sentiment label.\n",
        "        \"\"\"\n",
        "\n",
        "        # Get the relevant dicts for the sentiment\n",
        "        s_word_counts = self.word_counts[sentiment]\n",
        "        s_bigram_counts = self.bigram_counts[sentiment]\n",
        "        s_bigram_denoms = self.bigram_denoms[sentiment]\n",
        "        tokens = tokenize(sentence)\n",
        "        for token in tokens:\n",
        "            self.total_words[sentiment] += 1\n",
        "            s_word_counts[token] = s_word_counts.get(token, 0) + 1\n",
        "        my_bigrams = bigrams(tokens)\n",
        "        for bigram in my_bigrams:\n",
        "            s_bigram_counts[bigram] = s_bigram_counts.get(bigram, 0) + 1\n",
        "            s_bigram_denoms[bigram[0]] = s_bigram_denoms.get(bigram[0], 0) + 1\n",
        "            self.total_bigrams[sentiment] += 1\n",
        "       \n",
        "def get_models(df):\n",
        "    \"\"\"Returns a model_info object, consuming dataframe for examples.\"\"\"\n",
        "    last_fresh = 0\n",
        "    info = ModelInfo()\n",
        "    for _, line in df.iterrows():\n",
        "        try:\n",
        "            sentence_num = int(line['SentenceId'])\n",
        "            if sentence_num <= last_fresh:\n",
        "                continue\n",
        "            last_fresh = sentence_num\n",
        "            sentiment = int(line['Sentiment'])\n",
        "            info.sentiment_counts[sentiment] += 1\n",
        "            info.total_examples += 1\n",
        "            info.update_word_counts(line['Phrase'], sentiment)\n",
        "        except ValueError:\n",
        "            # Some kind of bad input?  Unlikely with our provided data\n",
        "            continue\n",
        "    return info"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk==3.4 in /usr/local/lib/python3.7/dist-packages (3.4)\n",
            "Requirement already satisfied: singledispatch in /usr/local/lib/python3.7/dist-packages (from nltk==3.4) (3.7.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.4) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbDFkUPuVVGx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e5bbfe8-160f-4ddf-e81e-b1829ac193c3"
      },
      "source": [
        "info = get_models(df)\n",
        "print(info)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "words by sentiment: [20448, 42045, 29947, 45550, 24054] sentences: [1072, 2200, 1655, 2321, 1281]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izfKDOyI1G45"
      },
      "source": [
        "In the following code, you just need to implement naive_bayes_classify() and markov_model_classify().  Notice the counts helpfully provided for you in the ModelInfo class; you should be able to calculate everything you need with those.\n",
        "\n",
        "The \"log probabilities\" that these functions use and return aren't exactly true probabilities.  In a Naive Bayes classifier, we calculate numbers that are proportional to the true probabilities; the largest number corresponds to the most likely class.  So don't try to rescale these to sum to 1 across the sentiments; for larger texts to classify, this wouldn't work because of underflow.  And, speaking of underflow, please take the log of each term and add, rather than taking the log after multiplying everything out, since the whole point of taking logs is to avoid underflow, and waiting until after you've multiplied everything is too late.\n",
        "\n",
        "The two key equations for the models are, for the Naive Bayes model,\n",
        "\n",
        "$Pr(sentiment = c | words) \\propto Pr(sentiment = c) \\prod Pr(word_i |sentiment)$\n",
        "\n",
        "and for the Markov model,\n",
        "\n",
        "$Pr(sentiment = c | words) \\propto Pr(sentiment = c) Pr(word_1 | sentiment = c) \\prod Pr(word_i | word_{i-1}, sentiment = c)$\n",
        "\n",
        "The \"log probabilities\" are the logs of the expressions on the right, although again, you should sum over logs instead of taking a log of the product.  All of these conditional probabilities can be calculated by counting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVb-RjDmtU7I"
      },
      "source": [
        "\"\"\" Doing some Naive Bayes and Markov Models to do basic sentiment analysis.\n",
        "\n",
        "Input from train.tsv.zip at\n",
        "https:#www.kaggle.com/c/sentiment-analysis-on-movie-reviews\n",
        "\n",
        "itself gathered from the Rotten Tomatoes movie review aggregation site.\n",
        "\n",
        "Format is PhraseID[unused]   SentenceID  Sentence[tokenized] Sentiment\n",
        "\n",
        "We'll only use the first line for each SentenceID, since the others are\n",
        "micro-analyzed phrases that would just mess up our counts.\n",
        "\n",
        "Sentiment is on a 5-point scale:\n",
        "0 - negative\n",
        "1 - somewhat negative\n",
        "2 - neutral\n",
        "3 - somewhat positive\n",
        "4 - positive\n",
        "\n",
        "For each kind of model, we'll build one model per sentiment category.\n",
        "Following Bayesian logic, base rates matter for each category; if critics\n",
        "are often negative, that should be a good guess in the absence of other\n",
        "information.\n",
        "\n",
        "Training input is assumed to be in a file called \"train.tsv\"\n",
        "\n",
        "Test sentences are received via stdin (thus either interactively or with input redirection).\n",
        "Output for each line of input is the following:\n",
        "\n",
        "Naive Bayes classification (0-4)\n",
        "Naive Bayes most likely class's log probability (with default double digits/precision)\n",
        "Markov Model classification (0-4)\n",
        "Markov Model most likely class's log probability\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "import math\n",
        "\n",
        "CLASSES = 5\n",
        "# Assume sentence numbering starts with this number in the file\n",
        "\n",
        "# Probability of either a unigram or bigram that hasn't been seen -\n",
        "# needs to be small enough that it's \"practically a rounding error\"\n",
        "OUT_OF_VOCAB_PROB = 0.0000000001\n",
        "\n",
        "def naive_bayes_classify(info, sentence):\n",
        "    \"\"\" Use a Naive Bayes model to return sentence's most likely classification and the log prob.\n",
        "\n",
        "    The log probability should be base e (natural log).\n",
        "\n",
        "    Args:\n",
        "        info (ModelInfo):  a ModelInfo containing the counts from the training data\n",
        "        sentence (string):  the test sentence to classify\n",
        "\n",
        "    Returns:\n",
        "        int for the best sentiment\n",
        "        float for the best log probability (unscaled, just ln(prior * product of cond. probs))\n",
        "    \"\"\"\n",
        "    # Pr(sentiment=c|words)∝Pr(sentiment=c)∏Pr(wordi|sentiment)\n",
        "    prob = []\n",
        "    for x in info.sentiment_counts:\n",
        "      prob.append(math.log(x / info.total_examples, math.e))\n",
        "\n",
        "    words = tokenize(sentence)\n",
        "    for i in words:\n",
        "        for c in range(CLASSES):\n",
        "            prob_i = info.word_counts[c].get(i, 0) / info.total_words[c]\n",
        "            if (prob_i == 0):\n",
        "                prob[c] += math.log(OUT_OF_VOCAB_PROB, math.e)\n",
        "            else:\n",
        "                prob[c] += math.log(prob_i, math.e)\n",
        "\n",
        "    # Best sentiment, best log probability.\n",
        "    return prob.index(max(prob)), max(prob)\n",
        "\n",
        "\n",
        "def markov_model_classify(info, sentence):\n",
        "    \"\"\" Like naive_bayes_classify, but use a bigram model for the evidence.\n",
        "\n",
        "    The first word should still use a unigram probability to get started.\n",
        "    Notice the existence of bigram_denoms, which has very slight differences from word_counts.\n",
        "    Log probability is again base e.\n",
        "\n",
        "    Args:\n",
        "        info (ModelInfo):  a ModelInfo containing the counts from the training data\n",
        "        sentence (string):  the test sentence to classify\n",
        "\n",
        "    Returns:\n",
        "        int for the best sentiment\n",
        "        float for the best log probability (unscaled, just ln(prior * product of cond. probs))\n",
        "    \"\"\"\n",
        "    # Pr(sentiment=c|words)∝Pr(sentiment=c)Pr(word1|sentiment=c)∏Pr(wordi|wordi−1,sentiment=c)\n",
        "    prob = []\n",
        "    for x in info.sentiment_counts:\n",
        "      prob.append(math.log(x / info.total_examples, math.e))\n",
        "\n",
        "    words = tokenize(sentence)\n",
        "    my_bigrams = bigrams(words)\n",
        "    i = words[0]\n",
        "    for c in range(CLASSES):\n",
        "        prob_i = info.word_counts[c].get(i, 0) / info.total_words[c]\n",
        "        if prob_i == 0:\n",
        "            prob[c] += math.log(OUT_OF_VOCAB_PROB, math.e)\n",
        "        else:\n",
        "            prob[c] += math.log(prob_i, math.e)\n",
        "\n",
        "    # \"Notic[ing] the existence of bigram_denoms.\"\n",
        "    for bigram in my_bigrams:\n",
        "        for c in range(CLASSES):\n",
        "            counts = info.bigram_counts[c].get(bigram, 0)\n",
        "            denoms = info.bigram_denoms[c].get(bigram[0], 0)\n",
        "            if counts != 0:\n",
        "                prob_bigrams = counts / denoms\n",
        "            else:\n",
        "                prob_bigrams = OUT_OF_VOCAB_PROB\n",
        "            prob[c] += math.log(prob_bigrams, math.e)\n",
        "\n",
        "    # Best sentiment, best log probability.\n",
        "    return prob.index(max(prob)), max(prob)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc6GCAQK31t3"
      },
      "source": [
        "Here are some sample sentences to test on, using the full dataset.  Note that it's possible to make minor mistakes, such as forgetting the prior, and still classify correctly, so just use this as a rough guide as to whether you're in the right ballpark."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rm0YHge64Yeo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11c7b25d-ccaf-4334-f556-c4443325e2bc"
      },
      "source": [
        "test1 = \"this is a terrible movie\"  # expect 0, negative\n",
        "test2 = \"this is a delightful , joyous romp\" # expect 4, very positive\n",
        "test3 = \"the dialogue stumbles occasionally , but usually delivers\" # expect 2, neutral\n",
        "# test4: expect 0 for basic nb, 2 for Markov (and true sentiment is more like a 4)\n",
        "test4 = \"I can't think of a single reason not to watch this movie\"\n",
        "print(naive_bayes_classify(info, test1))\n",
        "print(naive_bayes_classify(info, test2))\n",
        "print(naive_bayes_classify(info, test3))\n",
        "print(naive_bayes_classify(info, test4))\n",
        "print(markov_model_classify(info, test1))\n",
        "print(markov_model_classify(info, test2))\n",
        "print(markov_model_classify(info, test3))\n",
        "print(markov_model_classify(info, test4))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, -27.002316729069577)\n",
            "(4, -42.912159360571394)\n",
            "(2, -56.43702265463601)\n",
            "(0, -87.1044437764929)\n",
            "(0, -17.643654407813663)\n",
            "(4, -24.87612307805379)\n",
            "(2, -107.25356901908081)\n",
            "(2, -120.66613835938307)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgauhmlJav_3"
      },
      "source": [
        "If things are going wrong, it may be easier to use a small training file to test, where you can manually count and calculate probabilities.  The following example shows how to create a text test file in the notebook itself, converting it to a dataframe.  The expected sentiments aren't provided - the input is small enough that you could calculate the expected log probabilities with a calculator.  This input will also be used for grading."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8mNyiDibwFr"
      },
      "source": [
        "from io import StringIO\n",
        "testinput = \"\"\"PhraseId\\tSentenceId\\tPhrase\\tSentiment\n",
        "1\\t1\\tamazing exciting movie hurrah\\t4\n",
        "2\\t2\\tjust amazing not sure how else to describe it\\t4\n",
        "3\\t3\\ta good time is guaranteed for everyone\\t4\n",
        "4\\t4\\tpretty good but not for everyone\\t3\n",
        "5\\t5\\tpretty clear this is not for everyone\\t2\n",
        "6\\t6\\tpretty thoroughly average movie\\t2\n",
        "7\\t7\\tnot sure why this movie was made\\t1\n",
        "8\\t8\\tthis movie should never have been made\\t0\n",
        "9\\t9\\tit is amazing how bad this movie is\\t0\"\"\"\n",
        "\n",
        "test_df = pd.read_table(StringIO(testinput))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CML2CMc_b83P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "9ce94957-8488-48d6-dc19-42514c5e4afe"
      },
      "source": [
        "test_df"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>amazing exciting movie hurrah</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>just amazing not sure how else to describe it</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>a good time is guaranteed for everyone</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>pretty good but not for everyone</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>pretty clear this is not for everyone</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>pretty thoroughly average movie</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>not sure why this movie was made</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>this movie should never have been made</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>it is amazing how bad this movie is</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...  Sentiment\n",
              "0         1  ...          4\n",
              "1         2  ...          4\n",
              "2         3  ...          4\n",
              "3         4  ...          3\n",
              "4         5  ...          2\n",
              "5         6  ...          2\n",
              "6         7  ...          1\n",
              "7         8  ...          0\n",
              "8         9  ...          0\n",
              "\n",
              "[9 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxw3GMOtigDg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "047313c9-e940-46bf-b6f8-ad274adcfe3b"
      },
      "source": [
        "test_info = get_models(test_df)\n",
        "print(test_info)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "words by sentiment: [15, 7, 11, 6, 20] sentences: [2, 1, 2, 1, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zo3Q0leedJnI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9aaebc7-a769-4138-8d6a-5ce59477b730"
      },
      "source": [
        "test5 = \"just amazing\"\n",
        "test6 = \"not amazing\"\n",
        "test7 = \"not for everyone\"\n",
        "test8 = \"ugh\"\n",
        "print(naive_bayes_classify(test_info, test5))\n",
        "print(naive_bayes_classify(test_info, test6))\n",
        "print(naive_bayes_classify(test_info, test7))\n",
        "print(naive_bayes_classify(test_info, test8))\n",
        "print(markov_model_classify(test_info, test5))\n",
        "print(markov_model_classify(test_info, test6))\n",
        "print(markov_model_classify(test_info, test7))\n",
        "print(markov_model_classify(test_info, test8))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, -6.396929655216146)\n",
            "(4, -6.396929655216146)\n",
            "(3, -7.5725029850203835)\n",
            "(4, -24.124463218608568)\n",
            "(4, -4.0943445622221)\n",
            "(2, -26.9278235995151)\n",
            "(2, -3.901972669574645)\n",
            "(4, -24.124463218608568)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tg074TeInbet"
      },
      "source": [
        "When you're confident your two methods are implemented correctly, **download the notebook and submit to Canvas**.\n",
        "\n",
        "Sentiment analysis is a task that has many easy examples, but also hard examples that could stump even humans.  Naive Bayes is good for problems where you expect the relationship between the input and the classification to be relatively straightforward, or you're willing to tolerate incorrect classifications on some moderate to hard examples.  It's also very much on the easier side of ML to debug."
      ]
    }
  ]
}